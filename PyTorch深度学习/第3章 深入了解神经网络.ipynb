{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 详解神经网络的组成部分\n",
    "\n",
    "## 1.1 层 —— 神经网络的基本组成"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98207865f45b660e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(Parameter containing:\n tensor([[-0.1093, -0.2341,  0.1806,  0.2400, -0.2131, -0.2347,  0.2537, -0.0582,\n          -0.0757, -0.0850],\n         [-0.1884,  0.2147,  0.2702, -0.0637,  0.2283,  0.1969, -0.1904,  0.1933,\n           0.1495,  0.2835],\n         [-0.1350,  0.0072, -0.1603,  0.0334, -0.0517,  0.1345, -0.0337, -0.3087,\n           0.2901,  0.1656],\n         [ 0.1759, -0.2352,  0.2515, -0.1472,  0.1112, -0.3137, -0.2840,  0.0612,\n          -0.1526,  0.2599],\n         [ 0.1245,  0.2647,  0.1110, -0.1463, -0.1335, -0.0825,  0.0082, -0.1154,\n          -0.2485,  0.1287]], device='mps:0', requires_grad=True),\n Parameter containing:\n tensor([ 0.1394,  0.1253,  0.0173, -0.0545, -0.1697], device='mps:0',\n        requires_grad=True))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch\n",
    "\n",
    "DEFAULT_DEVICE = 'mps'\n",
    "\n",
    "layer = Linear(in_features=10, out_features=5, bias=True, device=DEFAULT_DEVICE)\n",
    "\n",
    "layer(torch.randn(1, 10, device=DEFAULT_DEVICE))\n",
    "\n",
    "layer.weight, layer.bias"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:37:25.057577Z",
     "start_time": "2023-11-23T09:37:24.956452Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "一些流行的非线性函数：\n",
    "* sigmoid\n",
    "* tanh\n",
    "* ReLU\n",
    "* Leaky ReLU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41144a0d9b444a63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 PyTorch 中的非线性激活函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74b519bff9ccc181"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 2., 0., 0.])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import ReLU, MSELoss\n",
    "\n",
    "simple_data = torch.Tensor([1, 2, -1, -1])\n",
    "\n",
    "relu = ReLU()\n",
    "relu(simple_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:37:25.058027Z",
     "start_time": "2023-11-23T09:37:24.987020Z"
    }
   },
   "id": "b06e15406d7c22ef"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(4.1083, grad_fn=<MseLossBackward0>), None)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss = MSELoss()\n",
    "\n",
    "X = torch.randn(3, 5, requires_grad=True)\n",
    "y = torch.randn(3, 5)\n",
    "\n",
    "output = mse_loss(X, y)\n",
    "\n",
    "output, output.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:37:25.058392Z",
     "start_time": "2023-11-23T09:37:24.991792Z"
    }
   },
   "id": "452377158dc17783"
  },
  {
   "cell_type": "markdown",
   "source": [
    "PyTorch 提供的优化器\n",
    "* ADADELTA\n",
    "* Adagrad\n",
    "* Adam\n",
    "* SparseAdam\n",
    "* Adamax\n",
    "* ASGD\n",
    "* LBFGS\n",
    "* RMSProp\n",
    "* Rprop\n",
    "* SGD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56e1c99458ea17f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 使用深度学习对图像进行分类\n",
    "\n",
    "处理数据集，处理成 ImageFolder 可以处理的路径格式。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786c72d5edc7b498"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/WTTCH/数据集/archive/PetImages'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 20\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_valid_file\u001B[39m(file: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m._\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m file\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjpg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m full_images \u001B[38;5;241m=\u001B[39m \u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDOG_CAT_DATASET_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msimple_transform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m full_images\u001B[38;5;241m.\u001B[39mclass_to_idx, full_images\u001B[38;5;241m.\u001B[39mclasses\n",
      "File \u001B[0;32m~/workspace/PG/ENV/AI@3.11/lib/python3.11/site-packages/torchvision/datasets/folder.py:309\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    303\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    307\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    308\u001B[0m ):\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[0;32m~/workspace/PG/ENV/AI@3.11/lib/python3.11/site-packages/torchvision/datasets/folder.py:144\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    136\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    141\u001B[0m     is_valid_file: Optional[Callable[[\u001B[38;5;28mstr\u001B[39m], \u001B[38;5;28mbool\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    142\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transform\u001B[38;5;241m=\u001B[39mtransform, target_transform\u001B[38;5;241m=\u001B[39mtarget_transform)\n\u001B[0;32m--> 144\u001B[0m     classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_dataset(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, class_to_idx, extensions, is_valid_file)\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;241m=\u001B[39m loader\n",
      "File \u001B[0;32m~/workspace/PG/ENV/AI@3.11/lib/python3.11/site-packages/torchvision/datasets/folder.py:218\u001B[0m, in \u001B[0;36mDatasetFolder.find_classes\u001B[0;34m(self, directory)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(\u001B[38;5;28mself\u001B[39m, directory: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[1;32m    192\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001B[39;00m\n\u001B[1;32m    193\u001B[0m \n\u001B[1;32m    194\u001B[0m \u001B[38;5;124;03m        directory/\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001B[39;00m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/PG/ENV/AI@3.11/lib/python3.11/site-packages/torchvision/datasets/folder.py:40\u001B[0m, in \u001B[0;36mfind_classes\u001B[0;34m(directory)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(directory: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[1;32m     36\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \n\u001B[1;32m     38\u001B[0m \u001B[38;5;124;03m    See :class:`DatasetFolder` for details.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m     classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(entry\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mis_dir())\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find any class folder in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Volumes/WTTCH/数据集/archive/PetImages'"
     ]
    }
   ],
   "source": [
    "from dot_cat_dataset import DOG_CAT_DATASET_PATH\n",
    "from glob import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "\n",
    "# 数据转换，图片转换为张量并正则化\n",
    "simple_transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def is_valid_file(file: str):\n",
    "    return not file.split('/')[-1].startswith(\"._\") and file.endswith('jpg')\n",
    "\n",
    "\n",
    "full_images = ImageFolder(DOG_CAT_DATASET_PATH, transform=simple_transform, is_valid_file=is_valid_file)\n",
    "\n",
    "full_images.class_to_idx, full_images.classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T09:37:25.059433Z",
     "start_time": "2023-11-23T09:37:24.998603Z"
    }
   },
   "id": "5c1c7e063a0d9cd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "将张量可视化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df96c9f0fa1cf960"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def imshow(inp: torch.Tensor):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "\n",
    "imshow(full_images[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T09:37:25.033329Z"
    }
   },
   "id": "63a6514ea85501f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "切分数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63d811aae8386fc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataset, test_dataset = random_split(full_images, [23000, len(full_images) - 23000]) # type: Subset, Subset\n",
    "train_dataset, test_dataset = random_split(full_images, [1000, 200]) # type: Subset, Subset\n",
    "\n",
    "train_data_gen = DataLoader(train_dataset, batch_size=64, num_workers=3, shuffle=True)\n",
    "test_data_gen = DataLoader(test_dataset, batch_size=64, num_workers=3, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T09:37:25.036261Z"
    }
   },
   "id": "e0bdad1b5a705eef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用 ResNet 神经网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d180539232de6226"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "model_ft = resnet18(weights=[ResNet18_Weights.DEFAULT], progress=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft.to(device='mps')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T09:37:25.038772Z"
    }
   },
   "id": "cd7ad03902203fa9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练模型:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf40172aa7bf4ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model: nn.Module, loss_fn: _Loss, optimizer: optim.Optimizer, dataset: DataLoader):\n",
    "    size = len(dataset.dataset.dataset)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataset):\n",
    "        X = X.to(device='mps')\n",
    "        y = y.to(device='mps')\n",
    "        # 计算\n",
    "        pred = model(X)\n",
    "        # 损失\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 收集梯度\n",
    "        optimizer.step()\n",
    "        # 梯度归零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss, current = loss.item(), (batch + 1) * len(X)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T09:37:25.040713Z"
    }
   },
   "id": "4ced03d3cee7993c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 损失函数和优化器\n",
    "learning_rate = 0.001\n",
    "cross_entropy_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "\n",
    "train_model(model_ft, cross_entropy_loss_fn, optimizer_ft, train_data_gen)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T09:37:25.041820Z"
    }
   },
   "id": "5d5461b7bd3e8578"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-23T09:37:25.043210Z"
    }
   },
   "id": "3a62a9151d7b564e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
